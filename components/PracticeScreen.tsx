import { useState, useEffect } from 'react';
import { Button } from './ui/button';
import { GradientButton } from './GradientButton';
import { Card } from './ui/card';
import { ArrowLeft, Play, Pause, SkipForward, RotateCcw, Mic, MicOff, AlertCircle, Home } from 'lucide-react';
import { WaveformVisualizer } from './WaveformVisualizer';
import { getAccuracyColor } from './AccuracyBadge';
import { AccuracyColorBar } from './AccuracyColorBar';
import { Progress } from './ui/progress';
import { apiClient } from '../utils/api';
import { voiceApi } from '../utils/voiceApi';
import { useWavRecorder } from '../hooks/useWavRecorder';
import { speechOceanSentences, calculateRealisticScore } from '../data/speechocean-sentences';

// ë§ˆì´í¬ ìƒíƒœ í™•ì¸ í•¨ìˆ˜
const getMicrophonePermissionStatus = async (): Promise<string> => {
  try {
    const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
    return result.state;
  } catch {
    return 'prompt';
  }
};

interface Word {
  text: string;
  accuracy: number;
  startTime: number;
  endTime: number;
}

interface Sentence {
  text: string;
  pronunciation: string;
  difficulty: string;
}

interface PracticeScreenProps {
  userProfile?: any;
  clonedVoiceData?: { url: string; sampleText: string; audioBlob?: Blob; sessionId?: string } | null;
  onBack: () => void;
  onComplete: (sessionData: any) => void;
}

// ë ˆë²¨ë³„ ë¬¸ì¥ ìƒ˜í”Œë§ í•¨ìˆ˜
const getSampleSentences = (level: string, purpose: string): Sentence[] => {
  // SpeechOcean762 ë°ì´í„°ì—ì„œ ë ˆë²¨ê³¼ ëª©ì ì— ë§ëŠ” ë¬¸ì¥ë“¤ ê°€ì ¸ì˜¤ê¸°
  const levelKey = level as keyof typeof speechOceanSentences;
  const purposeKey = purpose === 'business' ? 'business' : 'conversation';
  
  let sentences: any[] = [];
  
  if (speechOceanSentences[levelKey] && speechOceanSentences[levelKey][purposeKey]) {
    sentences = speechOceanSentences[levelKey][purposeKey].slice(0, 8);
  } else if (speechOceanSentences.beginner && speechOceanSentences.beginner.conversation) {
    // fallback to beginner conversation
    sentences = speechOceanSentences.beginner.conversation.slice(0, 8);
  }

  // Convert to expected format
  return sentences.map(s => ({
    text: s.text,
    pronunciation: s.text.toLowerCase(), // Simple fallback for pronunciation
    difficulty: s.level
  }));
};

export function PracticeScreen({ userProfile, clonedVoiceData, onBack, onComplete }: PracticeScreenProps) {
  const [sessionId] = useState(() => {
    // í´ë¡œë‹ëœ ìŒì„± ë°ì´í„°ì— sessionIdê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if (clonedVoiceData?.sessionId) {
      console.log('âœ… íŠœí† ë¦¬ì–¼ì—ì„œ ì „ë‹¬ë°›ì€ sessionId ì‚¬ìš©:', clonedVoiceData.sessionId);
      return clonedVoiceData.sessionId;
    } else {
      const newSessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      console.log('âš ï¸ ìƒˆë¡œìš´ sessionId ìƒì„± (í´ë¡œë‹ëœ ìŒì„± ì‚¬ìš© ë¶ˆê°€):', newSessionId);
      return newSessionId;
    }
  });
  const [sentences] = useState<Sentence[]>(getSampleSentences(userProfile?.level || 'beginner', userProfile?.purpose || 'conversation'));
  const [currentSentenceIndex, setCurrentSentenceIndex] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentAudio, setCurrentAudio] = useState<HTMLAudioElement | null>(null);
  const [userPronunciations, setUserPronunciations] = useState<(Word[] | null)[]>(Array(8).fill(null));
  const [isLoading, setIsLoading] = useState(false);
  const [hasError, setHasError] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  const [clonedAudioUrl, setClonedAudioUrl] = useState<string | null>(null);
  const [isGeneratingAudio, setIsGeneratingAudio] = useState(false);
  const [originalRecordingUrl, setOriginalRecordingUrl] = useState<string | null>(null);
  const [isPlayingOriginal, setIsPlayingOriginal] = useState(false);
  const [lastRecordingBlob, setLastRecordingBlob] = useState<Blob | null>(null);

  const { isRecording, startRecording, stopRecording, resetRecording } = useWavRecorder();

  useEffect(() => {
    console.log('ğŸš€ PracticeScreen ë§ˆìš´íŠ¸ë¨:', {
      hasClonedVoiceData: !!clonedVoiceData,
      hasAudioBlob: !!clonedVoiceData?.audioBlob,
      sessionId: clonedVoiceData?.sessionId,
      sentencesLength: sentences.length,
      firstSentence: sentences[0]?.text
    });
    
    // Generate cloned audio for the first sentence when component mounts
    if (clonedVoiceData?.audioBlob && sentences.length > 0) {
      console.log('âœ… ì¡°ê±´ ë§Œì¡± - ì²« ë²ˆì§¸ ë¬¸ì¥ ìŒì„± í´ë¡œë‹ ì‹œì‘');
      generateClonedAudio(sentences[0].text);
    } else {
      console.warn('âŒ ì¡°ê±´ ë¶ˆë§Œì¡± - ìŒì„± í´ë¡œë‹ ê±´ë„ˆëœ€:', {
        hasAudioBlob: !!clonedVoiceData?.audioBlob,
        hasFirstSentence: sentences.length > 0
      });
    }
  }, [clonedVoiceData, sentences]);

  const checkMicrophoneAvailable = async () => {
    setIsLoading(true);
    
    try {
      // ê°„ë‹¨í•˜ê²Œ ê¶Œí•œ ì²´í¬ - ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ í‘œì‹œ
      const status = await getMicrophonePermissionStatus();
      console.log('Microphone permission status:', status);
      
      // ê¶Œí•œì´ ê±°ë¶€ëœ ê²½ìš°ì—ë§Œ ì—ëŸ¬ í‘œì‹œ
      if (status === 'denied') {
        setHasError(true);
        setErrorMessage('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        setIsLoading(false);
        return false;
      }
      
      setHasError(false);
      setErrorMessage('');
      setIsLoading(false);
      return true;
    } catch (error) {
      console.error('Microphone check failed:', error);
      // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì¼ë‹¨ ì§„í–‰ (ê¶Œí•œ í”„ë¡¬í”„íŠ¸ëŠ” ë…¹ìŒ ì‹œì‘í•  ë•Œ ë‚˜íƒ€ë‚¨)
      setHasError(false);
      setIsLoading(false);
      return true;
    }
  };

  const generateClonedAudio = async (text: string) => {
    console.log('ğŸ¯ generateClonedAudio í˜¸ì¶œë¨:', { 
      text, 
      hasClonedVoiceData: !!clonedVoiceData,
      hasAudioBlob: !!clonedVoiceData?.audioBlob,
      sessionId 
    });
    
    if (!clonedVoiceData?.audioBlob) {
      console.warn('âŒ clonedVoiceData ë˜ëŠ” audioBlobê°€ ì—†ìŠµë‹ˆë‹¤');
      return;
    }
    
    setIsGeneratingAudio(true);
    try {
      console.log('ğŸ¤ ìŒì„± í´ë¡œë‹ ì‹œì‘:', text);
      const result = await voiceApi.cloneVoice(clonedVoiceData.audioBlob, text, sessionId);
      console.log('âœ… ìŒì„± í´ë¡œë‹ ì„±ê³µ:', result);
      setClonedAudioUrl(result.url);
    } catch (error) {
      console.error('âŒ ìŒì„± í´ë¡œë‹ ì‹¤íŒ¨:', error);
      // ì—ëŸ¬ ìƒíƒœ í‘œì‹œ
      setHasError(true);
      setErrorMessage(`ìŒì„± í´ë¡œë‹ ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    } finally {
      setIsGeneratingAudio(false);
    }
  };

  const playAudio = async () => {
    if (isPlaying) {
      currentAudio?.pause();
      setIsPlaying(false);
      return;
    }

    const currentText = sentences[currentSentenceIndex]?.text;
    if (!currentText) return;

    setIsLoading(true);
    try {
      let audioUrl: string;
      
      // If we have cloned voice data, use it
      if (clonedVoiceData?.audioBlob && clonedAudioUrl) {
        audioUrl = clonedAudioUrl;
      } else {
        // Fallback to default TTS - use clone voice API without cloned audio
        const result = await voiceApi.cloneVoice(new Blob(), currentText);
        audioUrl = result.url;
      }

      const audio = new Audio(audioUrl);
      setCurrentAudio(audio);

      audio.onplay = () => setIsPlaying(true);
      audio.onended = () => setIsPlaying(false);
      audio.onerror = (e) => {
        console.error('Audio playback error:', e);
        setIsPlaying(false);
        setHasError(true);
        setErrorMessage('ì˜¤ë””ì˜¤ ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      };

      await audio.play();
    } catch (error) {
      console.error('Audio generation/playback failed:', error);
      setHasError(true);
      setErrorMessage('ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsLoading(false);
    }
  };

  const startPronunciationRecording = async () => {
    const micAvailable = await checkMicrophoneAvailable();
    if (!micAvailable) return;

    const success = await startRecording();
    if (!success) {
      setHasError(true);
      setErrorMessage('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopPronunciationRecording = async () => {
    const audioBlob = await stopRecording();
    if (!audioBlob) {
      setHasError(true);
      setErrorMessage('ë…¹ìŒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    setLastRecordingBlob(audioBlob);
    const recordingUrl = URL.createObjectURL(audioBlob);
    setOriginalRecordingUrl(recordingUrl);

    setIsLoading(true);
    try {
      const result = await voiceApi.analyzeVoice(audioBlob, sentences[currentSentenceIndex].text);
      
      // Use actual analysis results from API
      const words = result.word_analysis?.map((wordData: any) => ({
        text: wordData.word.replace(/[.,!?]/g, ''), // Remove punctuation
        accuracy: wordData.accuracy,
        startTime: wordData.start_time,
        endTime: wordData.end_time
      })) || sentences[currentSentenceIndex].text.split(' ').map((word, index) => ({
        text: word.replace(/[.,!?]/g, ''),
        accuracy: 85, // Fallback accuracy
        startTime: index * 0.5,
        endTime: (index + 1) * 0.5
      }));
      
      const newPronunciations = [...userPronunciations];
      newPronunciations[currentSentenceIndex] = words;
      setUserPronunciations(newPronunciations);
      setHasError(false);
    } catch (error) {
      console.error('Pronunciation analysis failed:', error);
      setHasError(true);
      setErrorMessage('ë°œìŒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsLoading(false);
    }
  };

  const goToNextSentence = () => {
    if (currentSentenceIndex < sentences.length - 1) {
      const nextIndex = currentSentenceIndex + 1;
      setCurrentSentenceIndex(nextIndex);
      
      // Generate cloned audio for the next sentence
      if (clonedVoiceData?.audioBlob && sentences[nextIndex]) {
        generateClonedAudio(sentences[nextIndex].text);
      }

      // Stop any currently playing audio
      if (currentAudio) {
        currentAudio.pause();
        setIsPlaying(false);
      }
    } else {
      // ë§ˆì§€ë§‰ ë¬¸ì¥ì—ì„œ ë‹¤ìŒì„ ëˆ„ë¥´ë©´ í•™ìŠµ ì™„ë£Œ
      completePractice();
    }
  };

  const goToPreviousSentence = () => {
    if (currentSentenceIndex > 0) {
      const prevIndex = currentSentenceIndex - 1;
      setCurrentSentenceIndex(prevIndex);
      
      // Generate cloned audio for the previous sentence
      if (clonedVoiceData?.audioBlob && sentences[prevIndex]) {
        generateClonedAudio(sentences[prevIndex].text);
      }

      // Stop any currently playing audio
      if (currentAudio) {
        currentAudio.pause();
        setIsPlaying(false);
      }
    }
  };

  const completePractice = () => {
    // Calculate session statistics
    const completedSentences = userPronunciations.filter(p => p !== null).length;
    const totalWords = userPronunciations
      .filter(p => p !== null)
      .reduce((sum, words) => sum + (words?.length || 0), 0);
    
    const totalAccuracy = userPronunciations
      .filter(p => p !== null)
      .reduce((sum, words) => {
        if (!words) return sum;
        const avgAccuracy = words.reduce((acc, word) => acc + word.accuracy, 0) / words.length;
        return sum + avgAccuracy;
      }, 0);

    const averageAccuracy = completedSentences > 0 ? totalAccuracy / completedSentences : 0;

    const sessionData = {
      sessionId: sessionId,
      completedSentences,
      totalSentences: sentences.length,
      averageAccuracy: Math.round(averageAccuracy),
      practiceTime: 300, // 5 minutes estimated
      sentences: sentences.map((sentence, index) => ({
        text: sentence.text,
        pronunciation: sentence.pronunciation,
        userPronunciation: userPronunciations[index],
        completed: userPronunciations[index] !== null
      }))
    };

    onComplete(sessionData);
  };

  const resetCurrentSentence = () => {
    const newPronunciations = [...userPronunciations];
    newPronunciations[currentSentenceIndex] = null;
    setUserPronunciations(newPronunciations);
    setHasError(false);
    resetRecording();
    if (originalRecordingUrl) {
      URL.revokeObjectURL(originalRecordingUrl);
      setOriginalRecordingUrl(null);
    }
    setLastRecordingBlob(null);
  };

  const currentSentence = sentences[currentSentenceIndex];
  const currentPronunciation = userPronunciations[currentSentenceIndex];
  const canGoNext = currentSentenceIndex < sentences.length - 1;
  const canGoPrevious = currentSentenceIndex > 0;
  const hasCompletedAll = userPronunciations.every(p => p !== null);

  if (!currentSentence) {
    return (
      <div className="min-h-screen bg-gray-50 dark:bg-gray-900 flex items-center justify-center">
        <div className="text-center">
          <AlertCircle className="h-12 w-12 text-red-500 mx-auto mb-4" />
          <p className="text-gray-600 dark:text-gray-400">ë¬¸ì¥ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
          <Button onClick={onBack} className="mt-4">
            <ArrowLeft className="h-4 w-4 mr-2" />
            ëŒì•„ê°€ê¸°
          </Button>
        </div>
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-gradient-to-b from-green-50 to-blue-50">
      <div className="w-full max-w-sm mx-auto px-4 py-6">
        {/* Header */}
        <div className="flex items-center justify-between mb-6">
          <Button variant="ghost" onClick={onBack} className="p-2">
            <ArrowLeft className="h-5 w-5" />
          </Button>
          <div className="flex items-center space-x-4">
            <h1 className="text-xl font-bold text-gray-800 dark:text-gray-200">ë°œìŒ ì—°ìŠµ</h1>
            <Button variant="ghost" onClick={onBack} className="p-2">
              <Home className="h-5 w-5" />
            </Button>
          </div>
        </div>

        {/* Progress */}
        <div className="mb-6">
          <div className="flex justify-between text-sm text-gray-600 dark:text-gray-400 mb-2">
            <span>ì§„í–‰ë¥ </span>
            <span>{currentSentenceIndex + 1} / {sentences.length}</span>
          </div>
          <Progress value={(currentSentenceIndex + 1) / sentences.length * 100} className="h-2" />
        </div>

        {/* Main Content Area */}
        <div className="bg-gradient-to-b from-blue-100 via-green-100 to-yellow-100 rounded-lg p-6 mb-6">
          {/* Sentence with word highlighting */}
          <div className="text-center mb-6">
            {currentPronunciation ? (
              <div className="text-lg font-medium leading-relaxed">
                {currentSentence.text.split(' ').map((word, index) => {
                  const cleanWord = word.replace(/[.,!?]/g, '');
                  const wordData = currentPronunciation.find(w => w.text === cleanWord);
                  const accuracy = wordData?.accuracy || 0;
                  
                  let bgColor = '';
                  if (accuracy >= 90) bgColor = 'bg-green-200';
                  else if (accuracy >= 80) bgColor = 'bg-yellow-200';
                  else if (accuracy >= 70) bgColor = 'bg-orange-200';
                  else bgColor = 'bg-red-200';
                  
                  return (
                    <span
                      key={index}
                      className={`inline-block mx-1 px-2 py-1 rounded ${bgColor}`}
                    >
                      {word}
                    </span>
                  );
                })}
              </div>
            ) : (
              <p className="text-lg font-medium text-gray-800 mb-3">
                {currentSentence.text}
              </p>
            )}
          </div>

          {/* Waveform Visualization */}
          <div className="flex justify-center mb-6">
            <div className="flex items-center space-x-1">
              {[...Array(8)].map((_, i) => (
                <div
                  key={i}
                  className={`w-1 bg-blue-500 rounded-full transition-all duration-300 ${
                    isRecording ? 'h-8 animate-pulse' : 'h-4'
                  }`}
                  style={{
                    animationDelay: `${i * 0.1}s`
                  }}
                />
              ))}
            </div>
          </div>

          {/* Audio Controls */}
          <div className="flex justify-center space-x-3 mb-4">
            <Button
              onClick={playAudio}
              disabled={isLoading || isGeneratingAudio}
              className="bg-blue-500 hover:bg-blue-600 text-white"
            >
              {isPlaying ? <Pause className="h-4 w-4" /> : <Play className="h-4 w-4" />}
              {isGeneratingAudio ? 'ìƒì„± ì¤‘...' : isPlaying ? 'ì¼ì‹œì •ì§€' : 'ë“£ê¸°'}
            </Button>
          </div>

          {/* Overall Score Display */}
          {currentPronunciation && (
            <div className="text-center mb-4">
              <div className="inline-flex items-center justify-center w-16 h-16 bg-blue-500 text-white rounded-full text-xl font-bold">
                {Math.round(currentPronunciation.reduce((sum, word) => sum + word.accuracy, 0) / currentPronunciation.length)}%
              </div>
              <p className="text-sm text-gray-600 mt-2">ë°œìŒ ì •í™•ë„</p>
              <p className="text-xs text-gray-500">ì¢‹ì•„í•´ìš”!</p>
              <p className="text-xs text-gray-400 mt-1">ì‹œë„ íšŸìˆ˜: {currentSentenceIndex + 1}/5</p>
              
              {/* ìƒ‰ìƒ ê°€ì´ë“œ */}
              <div className="mt-4 p-3 bg-white bg-opacity-70 rounded-lg">
                <p className="text-xs text-gray-600 mb-2">ë°œìŒ ì •í™•ë„ ê°€ì´ë“œ</p>
                <div className="flex justify-center space-x-4 text-xs">
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-green-200 rounded mr-1"></div>
                    <span>90%+</span>
                  </div>
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-yellow-200 rounded mr-1"></div>
                    <span>80-89%</span>
                  </div>
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-orange-200 rounded mr-1"></div>
                    <span>70-79%</span>
                  </div>
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-red-200 rounded mr-1"></div>
                    <span>~69%</span>
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* Recording Controls */}
        <div className="space-y-3 mb-6">
          <GradientButton
            onClick={isRecording ? stopPronunciationRecording : startPronunciationRecording}
            disabled={isLoading}
            className="w-full"
          >
            {isRecording ? <MicOff className="h-4 w-4 mr-2" /> : <Mic className="h-4 w-4 mr-2" />}
            {isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : 'ë°œìŒ ë…¹ìŒ'}
          </GradientButton>

          {currentPronunciation && (
            <Button
              onClick={resetCurrentSentence}
              variant="outline"
              className="w-full"
            >
              <RotateCcw className="h-4 w-4 mr-2" />
              ë‹¤ì‹œ ì‹œë„
            </Button>
          )}
        </div>

        {/* Error Display */}
        {hasError && (
          <Card className="p-4 mb-6 border-red-200 bg-red-50 dark:border-red-800 dark:bg-red-900/20">
            <div className="flex items-center text-red-600 dark:text-red-400">
              <AlertCircle className="h-4 w-4 mr-2 flex-shrink-0" />
              <p className="text-sm">{errorMessage}</p>
            </div>
          </Card>
        )}

        {/* Navigation */}
        <div className="flex justify-between space-x-3 mb-6">
          <Button
            onClick={goToPreviousSentence}
            disabled={!canGoPrevious}
            variant="outline"
            className="flex-1"
          >
            ì´ì „
          </Button>
          
          {currentSentenceIndex === sentences.length - 1 ? (
            <GradientButton
              onClick={completePractice}
              className="flex-1"
            >
              ì—°ìŠµ ì™„ë£Œ
            </GradientButton>
          ) : (
            <Button
              onClick={goToNextSentence}
              disabled={!canGoNext}
              className="flex-1 bg-blue-500 hover:bg-blue-600 text-white"
            >
              ë‹¤ìŒ ë¬¸ì¥
              <SkipForward className="h-4 w-4 ml-2" />
            </Button>
          )}
        </div>

        {/* Complete Practice */}
        {hasCompletedAll && (
          <GradientButton
            onClick={completePractice}
            className="w-full"
          >
            ì—°ìŠµ ì™„ë£Œ
          </GradientButton>
        )}

        {/* Loading Indicator */}
        {isLoading && (
          <div className="flex justify-center mt-4">
            <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-blue-500"></div>
          </div>
        )}
      </div>
    </div>
  );
}