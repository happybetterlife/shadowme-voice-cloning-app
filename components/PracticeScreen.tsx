import { useState, useEffect } from 'react';
import { Button } from './ui/button';
import { GradientButton } from './GradientButton';
import { Card } from './ui/card';
import { ArrowLeft, Play, Pause, SkipForward, RotateCcw, Mic, MicOff, AlertCircle, Home } from 'lucide-react';
import { WaveformVisualizer } from './WaveformVisualizer';
import { getAccuracyColor } from './AccuracyBadge';
import { AccuracyColorBar } from './AccuracyColorBar';
import { Progress } from './ui/progress';
import { apiClient } from '../utils/api';
import { voiceApi } from '../utils/voiceApi';
import { useWavRecorder } from '../hooks/useWavRecorder';
import { speechOceanSentences, calculateRealisticScore } from '../data/speechocean-sentences';

// ë§ˆì´í¬ ìƒíƒœ í™•ì¸ í•¨ìˆ˜
const getMicrophonePermissionStatus = async (): Promise<string> => {
  try {
    const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
    return result.state;
  } catch {
    return 'prompt';
  }
};

interface Word {
  text: string;
  accuracy: number;
  startTime: number;
  endTime: number;
}

interface Sentence {
  text: string;
  pronunciation: string;
  difficulty: string;
}

interface PracticeScreenProps {
  userProfile?: any;
  clonedVoiceData?: { url: string; sampleText: string; audioBlob?: Blob; sessionId?: string } | null;
  onBack: () => void;
  onComplete: (sessionData: any) => void;
}

// ë ˆë²¨ë³„ ë¬¸ì¥ ìƒ˜í”Œë§ í•¨ìˆ˜
const getSampleSentences = (level: string, purpose: string): Sentence[] => {
  // SpeechOcean762 ë°ì´í„°ì—ì„œ ë ˆë²¨ê³¼ ëª©ì ì— ë§ëŠ” ë¬¸ì¥ë“¤ ê°€ì ¸ì˜¤ê¸°
  const levelKey = level as keyof typeof speechOceanSentences;
  const purposeKey = purpose === 'business' ? 'business' : 'conversation';
  
  let sentences: any[] = [];
  
  if (speechOceanSentences[levelKey] && speechOceanSentences[levelKey][purposeKey]) {
    sentences = speechOceanSentences[levelKey][purposeKey].slice(0, 8);
  } else if (speechOceanSentences.beginner && speechOceanSentences.beginner.conversation) {
    // fallback to beginner conversation
    sentences = speechOceanSentences.beginner.conversation.slice(0, 8);
  }

  // Convert to expected format
  return sentences.map(s => ({
    text: s.text,
    pronunciation: s.text.toLowerCase(), // Simple fallback for pronunciation
    difficulty: s.level
  }));
};

export function PracticeScreen({ userProfile, clonedVoiceData, onBack, onComplete }: PracticeScreenProps) {
  const [sessionId] = useState(() => {
    // ğŸš¨ BYPASS: í”„ë¡œí•„ ë¬¸ì œ ìš°íšŒí•˜ê³  ì„¸ì…˜ ìƒì„±
    const emergencySessionId = 'emergency_voice_session';
    console.log('ğŸš¨ EMERGENCY: Supabase ìš°íšŒ ì„¸ì…˜ ìƒì„±:', emergencySessionId);
    console.log('ğŸš¨ userProfile ìƒíƒœ:', userProfile);
    console.log('ğŸš¨ clonedVoiceData ìƒíƒœ:', clonedVoiceData);
    return emergencySessionId;
  });
  const [sentences, setSentences] = useState<Sentence[]>([]);
  const [isLoadingSentences, setIsLoadingSentences] = useState(true);
  const [currentSentenceIndex, setCurrentSentenceIndex] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentAudio, setCurrentAudio] = useState<HTMLAudioElement | null>(null);
  const [userPronunciations, setUserPronunciations] = useState<(Word[] | null)[]>(Array(8).fill(null));
  const [isLoading, setIsLoading] = useState(false);
  const [hasError, setHasError] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  const [clonedAudioUrl, setClonedAudioUrl] = useState<string | null>(null);
  const [isGeneratingAudio, setIsGeneratingAudio] = useState(false);
  const [originalRecordingUrl, setOriginalRecordingUrl] = useState<string | null>(null);
  const [isPlayingOriginal, setIsPlayingOriginal] = useState(false);
  const [lastRecordingBlob, setLastRecordingBlob] = useState<Blob | null>(null);

  const { isRecording, startRecording, stopRecording, resetRecording } = useWavRecorder();

  useEffect(() => {
    console.log('ğŸš¨ EMERGENCY MODE: Supabase ìš°íšŒ ëª¨ë“œ ì‹œì‘');
    
    // ğŸš¨ ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì—ì„œ ì‚¬ìš©ì ìŒì„± ë°ì´í„° ì§ì ‘ ì°¾ê¸°
    const localVoiceData = localStorage.getItem('userVoiceData');
    const localAudioBlob = localStorage.getItem('userAudioBlob');
    
    console.log('ğŸš¨ ë¡œì»¬ ë°ì´í„° ì²´í¬:', {
      hasClonedVoiceData: !!clonedVoiceData,
      hasLocalVoiceData: !!localVoiceData,
      hasLocalAudioBlob: !!localAudioBlob,
      clonedVoiceDataSize: clonedVoiceData?.audioBlob?.size
    });
    
    // ğŸš¨ ì—¬ëŸ¬ ê²½ë¡œë¡œ ì‚¬ìš©ì ìŒì„± ì°¾ê¸°
    if (clonedVoiceData?.audioBlob) {
      console.log('ğŸ¤ Route 1: clonedVoiceDataì—ì„œ ìŒì„± ë°œê²¬');
      generateClonedAudio(sentences[0]?.text || 'Hello');
    } else if (localVoiceData) {
      console.log('ğŸ¤ Route 2: localStorageì—ì„œ ìŒì„± ë°œê²¬');
      generateClonedAudio(sentences[0]?.text || 'Hello');
    } else {
      console.warn('ğŸš¨ ëª¨ë“  ê²½ë¡œì—ì„œ ì‚¬ìš©ì ìŒì„± ì—†ìŒ - ê¸°ë³¸ TTS ì‚¬ìš©');
      generateClonedAudio(sentences[0]?.text || 'Hello');
    }
  }, [clonedVoiceData, sentences]);

  const checkMicrophoneAvailable = async () => {
    setIsLoading(true);
    
    try {
      // ê°„ë‹¨í•˜ê²Œ ê¶Œí•œ ì²´í¬ - ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ í‘œì‹œ
      const status = await getMicrophonePermissionStatus();
      console.log('Microphone permission status:', status);
      
      // ê¶Œí•œì´ ê±°ë¶€ëœ ê²½ìš°ì—ë§Œ ì—ëŸ¬ í‘œì‹œ
      if (status === 'denied') {
        setHasError(true);
        setErrorMessage('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        setIsLoading(false);
        return false;
      }
      
      setHasError(false);
      setErrorMessage('');
      setIsLoading(false);
      return true;
    } catch (error) {
      console.error('Microphone check failed:', error);
      // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì¼ë‹¨ ì§„í–‰ (ê¶Œí•œ í”„ë¡¬í”„íŠ¸ëŠ” ë…¹ìŒ ì‹œì‘í•  ë•Œ ë‚˜íƒ€ë‚¨)
      setHasError(false);
      setIsLoading(false);
      return true;
    }
  };

  const generateClonedAudio = async (text: string) => {
    console.log('ğŸ¯ ìŒì„± í´ë¡œë‹ ì‹œì‘:', { text, sessionId });
    
    setIsGeneratingAudio(true);
    
    try {
      // 1ë‹¨ê³„: ì‚¬ìš©ìê°€ ë°©ê¸ˆ ë…¹ìŒí•œ ìŒì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©
      if (lastRecordingBlob) {
        console.log('ğŸ¤ ë°©ê¸ˆ ë…¹ìŒí•œ ìŒì„±ìœ¼ë¡œ í´ë¡œë‹ ì‹œë„:', {
          size: lastRecordingBlob.size,
          type: lastRecordingBlob.type
        });
        
        const result = await voiceApi.cloneVoice(lastRecordingBlob, text, sessionId);
        setClonedAudioUrl(result.url);
        console.log('âœ… ë°©ê¸ˆ ë…¹ìŒ ìŒì„±ìœ¼ë¡œ í´ë¡œë‹ ì„±ê³µ!');
        return;
      }
      
      // 2ë‹¨ê³„: íŠœí† ë¦¬ì–¼ì—ì„œ ê°€ì ¸ì˜¨ ìŒì„± ë°ì´í„° ì‚¬ìš©
      if (clonedVoiceData?.audioBlob) {
        console.log('ğŸ“š íŠœí† ë¦¬ì–¼ ìŒì„±ìœ¼ë¡œ í´ë¡œë‹ ì‹œë„:', {
          size: clonedVoiceData.audioBlob.size,
          type: clonedVoiceData.audioBlob.type
        });
        
        const result = await voiceApi.cloneVoice(clonedVoiceData.audioBlob, text, sessionId);
        setClonedAudioUrl(result.url);
        console.log('âœ… íŠœí† ë¦¬ì–¼ ìŒì„±ìœ¼ë¡œ í´ë¡œë‹ ì„±ê³µ!');
        return;
      }
      
      // 3ë‹¨ê³„: ì‚¬ìš©ì ìŒì„±ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ TTS ì‚¬ìš©
      console.warn('âš ï¸ ì‚¬ìš©ì ìŒì„± ì—†ìŒ - ê¸°ë³¸ TTS ì‚¬ìš©');
      const response = await fetch('/api/generate-speech', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text, voice: 'default' })
      });
      
      if (response.ok) {
        const blob = await response.blob();
        const url = URL.createObjectURL(blob);
        setClonedAudioUrl(url);
        console.log('ğŸ”„ ê¸°ë³¸ TTSë¡œ ëŒ€ì²´ ì™„ë£Œ');
      } else {
        throw new Error('TTS ìƒì„± ì‹¤íŒ¨');
      }
      
    } catch (error) {
      console.error('âŒ ëª¨ë“  ìŒì„± ìƒì„± ì‹¤íŒ¨:', error);
      setHasError(true);
      setErrorMessage('ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsGeneratingAudio(false);
    }
  };

  const playAudio = async () => {
    if (isPlaying) {
      currentAudio?.pause();
      setIsPlaying(false);
      return;
    }

    const currentText = sentences[currentSentenceIndex]?.text;
    if (!currentText) return;

    setIsLoading(true);
    try {
      let audioUrl: string;
      
      // If we have cloned voice data, use it
      if (clonedVoiceData?.audioBlob && clonedAudioUrl) {
        audioUrl = clonedAudioUrl;
      } else {
        // Fallback to default TTS - use clone voice API without cloned audio
        const result = await voiceApi.cloneVoice(new Blob(), currentText);
        audioUrl = result.url;
      }

      const audio = new Audio(audioUrl);
      setCurrentAudio(audio);

      audio.onplay = () => setIsPlaying(true);
      audio.onended = () => setIsPlaying(false);
      audio.onerror = (e) => {
        console.error('Audio playback error:', e);
        setIsPlaying(false);
        setHasError(true);
        setErrorMessage('ì˜¤ë””ì˜¤ ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      };

      await audio.play();
    } catch (error) {
      console.error('Audio generation/playback failed:', error);
      setHasError(true);
      setErrorMessage('ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsLoading(false);
    }
  };

  const startPronunciationRecording = async () => {
    const micAvailable = await checkMicrophoneAvailable();
    if (!micAvailable) return;

    const success = await startRecording();
    if (!success) {
      setHasError(true);
      setErrorMessage('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopPronunciationRecording = async () => {
    const audioBlob = await stopRecording();
    if (!audioBlob) {
      setHasError(true);
      setErrorMessage('ë…¹ìŒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    console.log('ğŸ¤ ìƒˆë¡œìš´ ë…¹ìŒ ì™„ë£Œ:', { size: audioBlob.size, type: audioBlob.type });
    setLastRecordingBlob(audioBlob);
    const recordingUrl = URL.createObjectURL(audioBlob);
    setOriginalRecordingUrl(recordingUrl);

    // ğŸš€ ì¦‰ì‹œ ì´ ë…¹ìŒìœ¼ë¡œ ë‹¤ìŒ ë¬¸ì¥ í´ë¡œë‹ ì—…ë°ì´íŠ¸
    console.log('ğŸš€ ë…¹ìŒëœ ìŒì„±ìœ¼ë¡œ ì¦‰ì‹œ í´ë¡œë‹ ì—…ë°ì´íŠ¸ ì‹œì‘');
    
    setIsLoading(true);
    try {
      // ë°œìŒ ë¶„ì„
      const result = await voiceApi.analyzeVoice(audioBlob, sentences[currentSentenceIndex].text);
      
      const words = result.word_analysis?.map((wordData: any) => ({
        text: wordData.word.replace(/[.,!?]/g, ''),
        accuracy: wordData.accuracy,
        startTime: wordData.start_time,
        endTime: wordData.end_time
      })) || sentences[currentSentenceIndex].text.split(' ').map((word, index) => ({
        text: word.replace(/[.,!?]/g, ''),
        accuracy: 85,
        startTime: index * 0.5,
        endTime: (index + 1) * 0.5
      }));
      
      const newPronunciations = [...userPronunciations];
      newPronunciations[currentSentenceIndex] = words;
      setUserPronunciations(newPronunciations);
      
      // ğŸš€ ë‹¤ìŒ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ì´ ë…¹ìŒìœ¼ë¡œ ë¯¸ë¦¬ í´ë¡œë‹
      if (currentSentenceIndex < sentences.length - 1) {
        const nextText = sentences[currentSentenceIndex + 1].text;
        console.log('ğŸš€ ë‹¤ìŒ ë¬¸ì¥ ë¯¸ë¦¬ í´ë¡œë‹:', nextText);
        generateClonedAudio(nextText);
      }
      
      setHasError(false);
    } catch (error) {
      console.error('Pronunciation analysis failed:', error);
      setHasError(true);
      setErrorMessage('ë°œìŒ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setIsLoading(false);
    }
  };

  const goToNextSentence = () => {
    if (currentSentenceIndex < sentences.length - 1) {
      const nextIndex = currentSentenceIndex + 1;
      setCurrentSentenceIndex(nextIndex);
      
      // Generate cloned audio for the next sentence
      if (clonedVoiceData?.audioBlob && sentences[nextIndex]) {
        generateClonedAudio(sentences[nextIndex].text);
      }

      // Stop any currently playing audio
      if (currentAudio) {
        currentAudio.pause();
        setIsPlaying(false);
      }
    } else {
      // ë§ˆì§€ë§‰ ë¬¸ì¥ì—ì„œ ë‹¤ìŒì„ ëˆ„ë¥´ë©´ í•™ìŠµ ì™„ë£Œ
      completePractice();
    }
  };

  const goToPreviousSentence = () => {
    if (currentSentenceIndex > 0) {
      const prevIndex = currentSentenceIndex - 1;
      setCurrentSentenceIndex(prevIndex);
      
      // Generate cloned audio for the previous sentence
      if (clonedVoiceData?.audioBlob && sentences[prevIndex]) {
        generateClonedAudio(sentences[prevIndex].text);
      }

      // Stop any currently playing audio
      if (currentAudio) {
        currentAudio.pause();
        setIsPlaying(false);
      }
    }
  };

  const completePractice = () => {
    // Calculate session statistics
    const completedSentences = userPronunciations.filter(p => p !== null).length;
    const totalWords = userPronunciations
      .filter(p => p !== null)
      .reduce((sum, words) => sum + (words?.length || 0), 0);
    
    const totalAccuracy = userPronunciations
      .filter(p => p !== null)
      .reduce((sum, words) => {
        if (!words) return sum;
        const avgAccuracy = words.reduce((acc, word) => acc + word.accuracy, 0) / words.length;
        return sum + avgAccuracy;
      }, 0);

    const averageAccuracy = completedSentences > 0 ? totalAccuracy / completedSentences : 0;

    const sessionData = {
      sessionId: sessionId,
      completedSentences,
      totalSentences: sentences.length,
      averageAccuracy: Math.round(averageAccuracy),
      practiceTime: 300, // 5 minutes estimated
      sentences: sentences.map((sentence, index) => ({
        text: sentence.text,
        pronunciation: sentence.pronunciation,
        userPronunciation: userPronunciations[index],
        completed: userPronunciations[index] !== null
      }))
    };

    onComplete(sessionData);
  };

  const resetCurrentSentence = () => {
    const newPronunciations = [...userPronunciations];
    newPronunciations[currentSentenceIndex] = null;
    setUserPronunciations(newPronunciations);
    setHasError(false);
    resetRecording();
    if (originalRecordingUrl) {
      URL.revokeObjectURL(originalRecordingUrl);
      setOriginalRecordingUrl(null);
    }
    setLastRecordingBlob(null);
  };

  const currentSentence = sentences[currentSentenceIndex];
  const currentPronunciation = userPronunciations[currentSentenceIndex];
  const canGoNext = currentSentenceIndex < sentences.length - 1;
  const canGoPrevious = currentSentenceIndex > 0;
  const hasCompletedAll = userPronunciations.every(p => p !== null);

  if (!currentSentence) {
    return (
      <div className="min-h-screen bg-gray-50 dark:bg-gray-900 flex items-center justify-center">
        <div className="text-center">
          <AlertCircle className="h-12 w-12 text-red-500 mx-auto mb-4" />
          <p className="text-gray-600 dark:text-gray-400">ë¬¸ì¥ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
          <Button onClick={onBack} className="mt-4">
            <ArrowLeft className="h-4 w-4 mr-2" />
            ëŒì•„ê°€ê¸°
          </Button>
        </div>
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-gradient-to-b from-green-50 to-blue-50">
      <div className="w-full max-w-sm mx-auto px-4 py-6">
        {/* Header */}
        <div className="flex items-center justify-between mb-6">
          <Button variant="ghost" onClick={onBack} className="p-2">
            <ArrowLeft className="h-5 w-5" />
          </Button>
          <div className="flex items-center space-x-4">
            <h1 className="text-xl font-bold text-gray-800 dark:text-gray-200">ë°œìŒ ì—°ìŠµ</h1>
            <Button variant="ghost" onClick={onBack} className="p-2">
              <Home className="h-5 w-5" />
            </Button>
          </div>
        </div>

        {/* Progress */}
        <div className="mb-6">
          <div className="flex justify-between text-sm text-gray-600 dark:text-gray-400 mb-2">
            <span>ì§„í–‰ë¥ </span>
            <span>{currentSentenceIndex + 1} / {sentences.length}</span>
          </div>
          <Progress value={(currentSentenceIndex + 1) / sentences.length * 100} className="h-2" />
        </div>

        {/* Main Content Area */}
        <div className="bg-gradient-to-b from-blue-100 via-green-100 to-yellow-100 rounded-lg p-6 mb-6">
          {/* Sentence with word highlighting */}
          <div className="text-center mb-6">
            {currentPronunciation ? (
              <div className="text-lg font-medium leading-relaxed">
                {currentSentence.text.split(' ').map((word, index) => {
                  const cleanWord = word.replace(/[.,!?]/g, '');
                  const wordData = currentPronunciation.find(w => w.text === cleanWord);
                  const accuracy = wordData?.accuracy || 0;
                  
                  let bgColor = '';
                  if (accuracy >= 90) bgColor = 'bg-green-200';
                  else if (accuracy >= 80) bgColor = 'bg-yellow-200';
                  else if (accuracy >= 70) bgColor = 'bg-orange-200';
                  else bgColor = 'bg-red-200';
                  
                  return (
                    <span
                      key={index}
                      className={`inline-block mx-1 px-2 py-1 rounded ${bgColor}`}
                    >
                      {word}
                    </span>
                  );
                })}
              </div>
            ) : (
              <p className="text-lg font-medium text-gray-800 mb-3">
                {currentSentence.text}
              </p>
            )}
          </div>

          {/* Waveform Visualization */}
          <div className="flex justify-center mb-6">
            <div className="flex items-center space-x-1">
              {[...Array(8)].map((_, i) => (
                <div
                  key={i}
                  className={`w-1 bg-blue-500 rounded-full transition-all duration-300 ${
                    isRecording ? 'h-8 animate-pulse' : 'h-4'
                  }`}
                  style={{
                    animationDelay: `${i * 0.1}s`
                  }}
                />
              ))}
            </div>
          </div>

          {/* Audio Controls */}
          <div className="flex justify-center space-x-3 mb-4">
            <Button
              onClick={playAudio}
              disabled={isLoading || isGeneratingAudio}
              className="bg-blue-500 hover:bg-blue-600 text-white"
            >
              {isPlaying ? <Pause className="h-4 w-4" /> : <Play className="h-4 w-4" />}
              {isGeneratingAudio ? 'ìƒì„± ì¤‘...' : isPlaying ? 'ì¼ì‹œì •ì§€' : 'ë“£ê¸°'}
            </Button>
          </div>

          {/* Overall Score Display */}
          {currentPronunciation && (
            <div className="text-center mb-4">
              <div className="inline-flex items-center justify-center w-16 h-16 bg-blue-500 text-white rounded-full text-xl font-bold">
                {Math.round(currentPronunciation.reduce((sum, word) => sum + word.accuracy, 0) / currentPronunciation.length)}%
              </div>
              <p className="text-sm text-gray-600 mt-2">ë°œìŒ ì •í™•ë„</p>
              <p className="text-xs text-gray-500">ì¢‹ì•„í•´ìš”!</p>
              <p className="text-xs text-gray-400 mt-1">ì‹œë„ íšŸìˆ˜: {currentSentenceIndex + 1}/5</p>
              
              {/* ìƒ‰ìƒ ê°€ì´ë“œ */}
              <div className="mt-4 p-3 bg-white bg-opacity-70 rounded-lg">
                <p className="text-xs text-gray-600 mb-2">ë°œìŒ ì •í™•ë„ ê°€ì´ë“œ</p>
                <div className="flex justify-center space-x-4 text-xs">
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-green-200 rounded mr-1"></div>
                    <span>90%+</span>
                  </div>
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-yellow-200 rounded mr-1"></div>
                    <span>80-89%</span>
                  </div>
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-orange-200 rounded mr-1"></div>
                    <span>70-79%</span>
                  </div>
                  <div className="flex items-center">
                    <div className="w-3 h-3 bg-red-200 rounded mr-1"></div>
                    <span>~69%</span>
                  </div>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* Recording Controls */}
        <div className="space-y-3 mb-6">
          <GradientButton
            onClick={isRecording ? stopPronunciationRecording : startPronunciationRecording}
            disabled={isLoading}
            className="w-full"
          >
            {isRecording ? <MicOff className="h-4 w-4 mr-2" /> : <Mic className="h-4 w-4 mr-2" />}
            {isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : 'ë°œìŒ ë…¹ìŒ'}
          </GradientButton>

          {currentPronunciation && (
            <Button
              onClick={resetCurrentSentence}
              variant="outline"
              className="w-full"
            >
              <RotateCcw className="h-4 w-4 mr-2" />
              ë‹¤ì‹œ ì‹œë„
            </Button>
          )}
        </div>

        {/* Error Display */}
        {hasError && (
          <Card className="p-4 mb-6 border-red-200 bg-red-50 dark:border-red-800 dark:bg-red-900/20">
            <div className="flex items-center text-red-600 dark:text-red-400">
              <AlertCircle className="h-4 w-4 mr-2 flex-shrink-0" />
              <p className="text-sm">{errorMessage}</p>
            </div>
          </Card>
        )}

        {/* Navigation */}
        <div className="flex justify-between space-x-3 mb-6">
          <Button
            onClick={goToPreviousSentence}
            disabled={!canGoPrevious}
            variant="outline"
            className="flex-1"
          >
            ì´ì „
          </Button>
          
          {currentSentenceIndex === sentences.length - 1 ? (
            <GradientButton
              onClick={completePractice}
              className="flex-1"
            >
              ì—°ìŠµ ì™„ë£Œ
            </GradientButton>
          ) : (
            <Button
              onClick={goToNextSentence}
              disabled={!canGoNext}
              className="flex-1 bg-blue-500 hover:bg-blue-600 text-white"
            >
              ë‹¤ìŒ ë¬¸ì¥
              <SkipForward className="h-4 w-4 ml-2" />
            </Button>
          )}
        </div>

        {/* Complete Practice */}
        {hasCompletedAll && (
          <GradientButton
            onClick={completePractice}
            className="w-full"
          >
            ì—°ìŠµ ì™„ë£Œ
          </GradientButton>
        )}

        {/* Loading Indicator */}
        {isLoading && (
          <div className="flex justify-center mt-4">
            <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-blue-500"></div>
          </div>
        )}
      </div>
    </div>
  );
}