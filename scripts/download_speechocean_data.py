#!/usr/bin/env python3
"""
SpeechOcean762 ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ShadowME ì•±ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
from datasets import load_dataset
import pandas as pd
from typing import List, Dict, Any

def download_speechocean_data():
    """Hugging Faceì—ì„œ speechocean762 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
    print("ğŸ“¥ Downloading speechocean762 dataset...")
    
    try:
        # Hugging Faceì—ì„œ ë°ì´í„°ì…‹ ë¡œë“œ
        dataset = load_dataset("mispeech/speechocean762", split="test")
        print(f"âœ… Dataset loaded successfully! Total samples: {len(dataset)}")
        return dataset
    except Exception as e:
        print(f"âŒ Failed to download dataset: {e}")
        return None

def categorize_sentences_by_difficulty(dataset) -> Dict[str, List[Dict]]:
    """ë¬¸ì¥ì„ ë‚œì´ë„ë³„ë¡œ ë¶„ë¥˜"""
    sentences = {
        "beginner": [],
        "intermediate": [],
        "advanced": []
    }
    
    for item in dataset:
        text = item.get("text", "").strip()
        if not text:
            continue
            
        # ë¬¸ì¥ ê¸¸ì´ì™€ ë³µì¡ë„ë¡œ ë‚œì´ë„ ë¶„ë¥˜
        word_count = len(text.split())
        
        # ë°œìŒ í‰ê°€ ì ìˆ˜ í™œìš© (ìˆë‹¤ë©´)
        accuracy = item.get("accuracy", 0.7)  # ê¸°ë³¸ê°’ 0.7
        fluency = item.get("fluency", 0.7)
        
        sentence_data = {
            "id": len(sentences["beginner"]) + len(sentences["intermediate"]) + len(sentences["advanced"]) + 1,
            "text": text,
            "level": "",
            "purpose": "conversation",
            "target_accuracy": accuracy,
            "target_fluency": fluency,
            "word_count": word_count,
            "source": "speechocean762"
        }
        
        # ë‚œì´ë„ ë¶„ë¥˜ ë¡œì§
        if word_count <= 8 and accuracy >= 0.8:
            sentence_data["level"] = "beginner"
            sentences["beginner"].append(sentence_data)
        elif word_count <= 15 and accuracy >= 0.6:
            sentence_data["level"] = "intermediate"
            sentences["intermediate"].append(sentence_data)
        else:
            sentence_data["level"] = "advanced"
            sentences["advanced"].append(sentence_data)
    
    return sentences

def create_practice_sentences_file(sentences: Dict[str, List[Dict]]):
    """ì—°ìŠµìš© ë¬¸ì¥ íŒŒì¼ ìƒì„±"""
    
    # ê° ë ˆë²¨ì—ì„œ ìƒìœ„ ë¬¸ì¥ë“¤ë§Œ ì„ ë³„ (ë„ˆë¬´ ë§ìœ¼ë©´ ì•±ì´ ë¬´ê±°ì›Œì§)
    selected_sentences = {
        "beginner": {
            "conversation": sentences["beginner"][:20],  # ìƒìœ„ 20ê°œ
            "business": []  # ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì¥ì€ ë³„ë„ë¡œ ì¶”ê°€ ê°€ëŠ¥
        },
        "intermediate": {
            "conversation": sentences["intermediate"][:15],
            "business": []
        },
        "advanced": {
            "conversation": sentences["advanced"][:10],
            "business": []
        }
    }
    
    # TypeScript íŒŒì¼ë¡œ ìƒì„±
    ts_content = f"""// Generated from speechocean762 dataset
// Total sentences: {sum(len(v) for level in sentences.values() for v in level.values())}

export interface PracticeSentence {{
  id: string;
  text: string;
  level: string;
  purpose: string;
  targetWords?: string[];
  targetAccuracy?: number;
  targetFluency?: number;
  source?: string;
}}

export const speechOceanSentences: Record<string, Record<string, PracticeSentence[]>> = {json.dumps(selected_sentences, indent=2)};

// ë°œìŒ í‰ê°€ ê¸°ì¤€ì  (speechocean762 ë°ì´í„° ê¸°ë°˜)
export const pronunciationBenchmarks = {{
  excellent: 0.9,   // 90% ì´ìƒ
  good: 0.8,        // 80-89%
  fair: 0.7,        // 70-79%
  needsPractice: 0.6 // 60-69%
}};
"""
    
    output_file = "../data/speechocean-sentences.ts"
    os.makedirs("../data", exist_ok=True)
    
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(ts_content)
    
    print(f"âœ… Practice sentences saved to: {output_file}")
    return output_file

def create_supabase_migration(sentences: Dict[str, List[Dict]]):
    """Supabaseìš© SQL ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ìƒì„±"""
    
    sql_content = """-- SpeechOcean762 ë°ì´í„°ì…‹ ê¸°ë°˜ ì—°ìŠµ ë¬¸ì¥ í…Œì´ë¸”
CREATE TABLE IF NOT EXISTS practice_sentences (
    id SERIAL PRIMARY KEY,
    text TEXT NOT NULL,
    level TEXT NOT NULL CHECK (level IN ('beginner', 'intermediate', 'advanced')),
    purpose TEXT NOT NULL CHECK (purpose IN ('conversation', 'business', 'exam')),
    word_count INTEGER,
    target_accuracy DECIMAL(3,2),
    target_fluency DECIMAL(3,2),
    source TEXT DEFAULT 'speechocean762',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- ë°ì´í„° ì‚½ì…
"""
    
    for level, level_sentences in sentences.items():
        for sentence in level_sentences[:10]:  # ê° ë ˆë²¨ë‹¹ 10ê°œì”©ë§Œ
            text = sentence["text"].replace("'", "''")  # SQL ì´ìŠ¤ì¼€ì´í”„
            sql_content += f"""INSERT INTO practice_sentences (text, level, purpose, word_count, target_accuracy, target_fluency, source) 
VALUES ('{text}', '{level}', 'conversation', {sentence['word_count']}, {sentence.get('target_accuracy', 0.75)}, {sentence.get('target_fluency', 0.75)}, 'speechocean762');
"""
    
    migration_file = "../supabase/migrations/001_add_speechocean_sentences.sql"
    os.makedirs("../supabase/migrations", exist_ok=True)
    
    with open(migration_file, "w", encoding="utf-8") as f:
        f.write(sql_content)
    
    print(f"âœ… Supabase migration saved to: {migration_file}")
    return migration_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Starting SpeechOcean762 data processing for ShadowME...")
    
    # 1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    dataset = download_speechocean_data()
    if not dataset:
        return
    
    # 2. ë‚œì´ë„ë³„ ë¶„ë¥˜
    print("ğŸ“Š Categorizing sentences by difficulty...")
    sentences = categorize_sentences_by_difficulty(dataset)
    
    print(f"ğŸ“ˆ Statistics:")
    for level, level_sentences in sentences.items():
        print(f"  - {level.capitalize()}: {len(level_sentences)} sentences")
    
    # 3. TypeScript íŒŒì¼ ìƒì„± (ë¡œì»¬ ì‚¬ìš©)
    print("ğŸ“ Creating TypeScript data file...")
    create_practice_sentences_file(sentences)
    
    # 4. Supabase ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ìƒì„±
    print("ğŸ—„ï¸ Creating Supabase migration...")
    create_supabase_migration(sentences)
    
    print("ğŸ‰ Data processing completed successfully!")
    print("\nğŸ“‹ Next steps:")
    print("1. Install required packages: pip install datasets pandas")
    print("2. Run this script: python download_speechocean_data.py")
    print("3. Import the generated TypeScript file in your app")
    print("4. Or apply the Supabase migration for database storage")

if __name__ == "__main__":
    main()