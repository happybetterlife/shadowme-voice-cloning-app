import { NextRequest, NextResponse } from 'next/server';

const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY || "sk_a44152702031b3af9f1a87072171fc9993fdbfb477fba26c";

// API í‚¤ ìƒíƒœ ìì„¸íˆ í™•ì¸
console.log('ğŸ” DETAILED API KEY CHECK:');
console.log('  - process.env.ELEVENLABS_API_KEY exists:', !!process.env.ELEVENLABS_API_KEY);
console.log('  - Final ELEVENLABS_API_KEY used:', ELEVENLABS_API_KEY.substring(0, 15) + '...');
console.log('  - Key length:', ELEVENLABS_API_KEY.length);
console.log('  - Key starts with sk_:', ELEVENLABS_API_KEY.startsWith('sk_'));
const DEFAULT_VOICE_ID = "21m00Tcm4TlvDq8ikWAM"; // Rachel voice

// ì„¸ì…˜ë³„ í´ë¡œë‹ëœ ìŒì„± ì €ì¥ì†Œ (ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ)
const sessionVoiceCache = new Map<string, {
  voiceId: string;
  createdAt: number;
  lastUsed: number;
  sampleText: string;
}>();

// ìºì‹œ ì •ë¦¬ (24ì‹œê°„ í›„ ë§Œë£Œ) - ìŒì„± ì œí•œ ì ˆì•½ì„ ìœ„í•´ ì—°ì¥
const CACHE_TIMEOUT = 24 * 60 * 60 * 1000; // 24ì‹œê°„

// CORS í—¤ë” ì„¤ì •
export async function OPTIONS(request: NextRequest) {
  return new NextResponse(null, {
    status: 200,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type',
    },
  });
}

export async function POST(request: NextRequest) {
  let body: any;
  try {
    const startTime = Date.now();
    console.log('ğŸš¨ CRITICAL: Voice cloning request received (App Router)...');
    console.log('ğŸš¨ Request method:', request.method);
    console.log('ğŸš¨ Deploy timestamp:', new Date().toISOString());
    console.log('ğŸš¨ Environment check:');
    console.log('  - ELEVENLABS_API_KEY exists:', !!ELEVENLABS_API_KEY);
    console.log('  - ELEVENLABS_API_KEY length:', ELEVENLABS_API_KEY ? ELEVENLABS_API_KEY.length : 0);
    console.log('  - Current time:', new Date().toISOString());
    console.log('  - Vercel region:', process.env.VERCEL_REGION || 'unknown');
    console.log('  - Function timeout limit: 60 seconds (configured in vercel.json)');
    
    body = await request.json();
    console.log('ğŸš¨ Request body keys:', Object.keys(body));
    console.log('ğŸš¨ Request body size:', JSON.stringify(body).length);
    
    const { text = "Hello, how are you today?", audioData, sessionId } = body;
    
    console.log('ğŸš¨ EXTRACTED DATA:');
    console.log('  - text:', text);
    console.log('  - audioData exists:', !!audioData);
    console.log('  - audioData length:', audioData ? audioData.length : 0);
    console.log('  - sessionId:', sessionId);
    
    console.log('ğŸ“ Text received:', text);
    console.log('ğŸµ Audio data present:', !!audioData);
    console.log('ğŸµ Audio data type:', typeof audioData);
    console.log('ğŸµ Audio data length:', audioData ? audioData.length : 0);
    console.log('ğŸµ Audio data starts with:', audioData ? audioData.substring(0, 50) : 'N/A');
    console.log('ğŸ†” Session ID:', sessionId);
    
    if (!ELEVENLABS_API_KEY || ELEVENLABS_API_KEY.length === 0) {
      console.error('âŒ ELEVENLABS_API_KEY is not set!');
      return NextResponse.json({ error: 'API key not configured' }, { status: 500 });
    }

    if (!audioData || audioData.length < 100) {
      console.log('âŒ CRITICAL: No valid audio data provided, using default voice');
      console.log('ğŸ” Reason: audioData is', audioData ? `too short (${audioData.length} chars)` : 'missing');
      console.log('ğŸš¨ FALLBACK: Using default Rachel voice instead of user voice');
      return await generateWithDefaultVoice(text);
    }

    // ì„¸ì…˜ë³„ ìºì‹œëœ ìŒì„± í™•ì¸ (ì§€ì—°ì‹œê°„ ìµœì í™”)
    if (sessionId) {
      const cachedVoice = sessionVoiceCache.get(sessionId);
      if (cachedVoice && (Date.now() - cachedVoice.lastUsed) < CACHE_TIMEOUT) {
        console.log('âš¡ ìºì‹œëœ ìŒì„± ë°œê²¬! ì¦‰ì‹œ TTS ìƒì„±:', cachedVoice.voiceId);
        
        // ìºì‹œëœ ìŒì„±ìœ¼ë¡œ ì¦‰ì‹œ TTS ìƒì„± (í´ë¡œë‹ ë‹¨ê³„ ìƒëµ)
        const ttsResponse = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${cachedVoice.voiceId}`, {
          method: 'POST',
          headers: {
            'xi-api-key': ELEVENLABS_API_KEY,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            text,
            model_id: 'eleven_multilingual_v2',
            voice_settings: {
              stability: 0.7,
              similarity_boost: 0.8,
              style: 0.5,
              use_speaker_boost: true,
            },
          }),
        });

        if (ttsResponse.ok) {
          // ì‚¬ìš© ì‹œê°„ ì—…ë°ì´íŠ¸
          cachedVoice.lastUsed = Date.now();
          sessionVoiceCache.set(sessionId, cachedVoice);
          
          const audioBuffer = await ttsResponse.arrayBuffer();
          console.log('âœ…ğŸ‰ ìºì‹œëœ í´ë¡œë‹ ìŒì„±ìœ¼ë¡œ TTS ì™„ë£Œ (ì´ˆê³ ì†)');
          console.log('ğŸ—£ï¸ THIS IS YOUR CACHED CLONED VOICE!');
          return new NextResponse(audioBuffer, {
            headers: {
              'Content-Type': 'audio/mpeg',
              'Content-Disposition': 'attachment; filename="cached_cloned_voice.mp3"',
            },
          });
        } else {
          console.warn('âš ï¸ ìºì‹œëœ ìŒì„±ìœ¼ë¡œ TTS ì‹¤íŒ¨, ìŒì„± ì¬ìƒì„± í•„ìš”');
          // ìºì‹œ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
          sessionVoiceCache.delete(sessionId);
        }
      } else if (cachedVoice) {
        console.log('ğŸ—‘ï¸ ë§Œë£Œëœ ìºì‹œ ìŒì„± ì‚­ì œ:', sessionId);
        sessionVoiceCache.delete(sessionId);
        
        // ElevenLabsì—ì„œë„ ì •ë¦¬
        try {
          await fetch(`https://api.elevenlabs.io/v1/voices/${cachedVoice.voiceId}`, {
            method: 'DELETE',
            headers: { 'xi-api-key': ELEVENLABS_API_KEY },
          });
        } catch (e) { console.warn('ìŒì„± ì •ë¦¬ ì‹¤íŒ¨:', e); }
      }
    }

    // Convert base64 audio to buffer
    const audioBuffer = Buffer.from(audioData.split(',')[1], 'base64');
    console.log('ğŸ“ Audio data received, size:', audioBuffer.length);
    
    // ElevenLabs ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì²´í¬
    if (audioBuffer.length < 10000) { // 10KB ë¯¸ë§Œì´ë©´ ë„ˆë¬´ ì§§ìŒ
      console.warn('âš ï¸ Audio file too small for voice cloning:', audioBuffer.length, 'bytes');
      console.warn('âš ï¸ ElevenLabs requires at least 1-2 seconds of audio');
      return await generateWithDefaultVoice(text, `Audio file too small: ${audioBuffer.length} bytes (minimum: 10KB)`);
    }
    
    console.log('ğŸ§¬ Creating voice clone with ElevenLabs...');
    console.log('ğŸ“Š Environment check:');
    console.log('  - Runtime:', typeof process !== 'undefined' ? 'Node.js' : 'Browser');
    console.log('  - Platform:', typeof process !== 'undefined' ? process.platform : 'Unknown');
    console.log('  - Memory usage:', typeof process !== 'undefined' && process.memoryUsage ? process.memoryUsage() : 'Unknown');
    
    // ì‹¤í–‰ ì‹œê°„ ì²´í¬ - Vercel í•¨ìˆ˜ íƒ€ì„ì•„ì›ƒ ë°©ì§€
    const checkTimeout = () => {
      const elapsed = Date.now() - startTime;
      console.log(`â±ï¸ Elapsed time: ${elapsed}ms`);
      if (elapsed > 50000) { // 50ì´ˆ ê²½ê³¼ì‹œ ê²½ê³  (60ì´ˆ ì œí•œ)
        console.warn('âš ï¸ Approaching Vercel timeout limit (60s)!');
        return true;
      }
      return false;
    };

    // Step 1: Create voice clone using IVC (Instant Voice Cloning) 
    console.log('ğŸ§¬ Step 1: Creating voice clone...');
    if (checkTimeout()) {
      console.error('âŒ Timeout risk - using fallback voice');
      return await generateWithDefaultVoice(text);
    }
    
    // ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ì‹¤ì œ í˜•ì‹ ê°ì§€
    let fileExtension = 'webm';
    let mimeType = 'audio/webm';
    
    // Base64 í—¤ë”ì—ì„œ MIME íƒ€ì… ì¶”ì¶œ
    const base64Header = audioData.split(',')[0];
    if (base64Header.includes('audio/webm')) {
      fileExtension = 'webm';
      mimeType = 'audio/webm';
      console.log('ğŸµ WebM audio detected - ElevenLabs should handle this');
    } else if (base64Header.includes('audio/mp4')) {
      fileExtension = 'mp4';
      mimeType = 'audio/mp4';
      console.log('âš ï¸ MP4 audio detected - may cause compatibility issues');
    } else if (base64Header.includes('audio/aac')) {
      fileExtension = 'aac';
      mimeType = 'audio/aac';
      console.log('âš ï¸ AAC audio detected - may cause compatibility issues');
    } else {
      console.log('âš ï¸ Unknown audio format, defaulting to WebM');
    }
    
    console.log('ğŸµ Detected audio format:', { mimeType, fileExtension });
    console.log('ğŸ“¦ Audio buffer size:', audioBuffer.length, 'bytes');
    
    // Vercel í™˜ê²½ì—ì„œ FormData í˜¸í™˜ì„±ì„ ìœ„í•œ ê°œì„ ëœ ë°©ì‹
    const formData = new FormData();
    formData.append('name', `user_voice_${Date.now()}`);
    formData.append('description', 'User voice for pronunciation learning');
    
    // File ê°ì²´ë¡œ ìƒì„±í•˜ì—¬ í˜¸í™˜ì„± í–¥ìƒ
    const audioFile = new File([audioBuffer], `recording.${fileExtension}`, { 
      type: mimeType,
      lastModified: Date.now()
    });
    formData.append('files', audioFile);

    console.log('ğŸŒ Making ElevenLabs voice clone request...');
    console.log('ğŸ“Š FormData contents:');
    for (const [key, value] of formData.entries()) {
      if (value instanceof File) {
        console.log(`  - ${key}: File(name=${value.name}, size=${value.size}, type=${value.type})`);
      } else {
        console.log(`  - ${key}: ${value}`);
      }
    }
    
    const cloneResponse = await fetch('https://api.elevenlabs.io/v1/voices/add', {
      method: 'POST',
      headers: {
        'xi-api-key': ELEVENLABS_API_KEY,
      },
      body: formData,
    });
    
    if (checkTimeout()) {
      console.error('âŒ Timeout after voice clone request');
      return await generateWithDefaultVoice(text);
    }

    if (!cloneResponse.ok) {
      const errorText = await cloneResponse.text();
      console.error('âŒ Voice cloning failed:', errorText);
      console.error('âŒ Response status:', cloneResponse.status);
      console.error('âŒ Response headers:', Object.fromEntries(cloneResponse.headers.entries()));
      
      // ìƒì„¸í•œ ì˜¤ë¥˜ ë¶„ì„
      if (cloneResponse.status === 401) {
        console.error('ğŸ”‘ AUTHENTICATION ERROR: API key may be invalid or expired');
      } else if (cloneResponse.status === 429) {
        console.error('â° RATE LIMIT ERROR: Too many requests');
      } else if (cloneResponse.status === 402) {
        console.error('ğŸ’³ PAYMENT ERROR: Account may have reached quota limits');
      } else if (cloneResponse.status === 403 && errorText.includes('voice_add_edit_limit_reached')) {
        console.error('ğŸ“… MONTHLY LIMIT ERROR: ElevenLabs monthly voice cloning limit reached');
        console.error('ğŸ’¡ SOLUTION: Delete old voices or upgrade plan');
      } else if (errorText.includes('voice_limit_reached')) {
        console.error('ğŸ¤ VOICE LIMIT ERROR: Account has reached voice cloning limit');
      }
      
      // If voice limit reached, try to clean up old voices first
      if (errorText.includes('voice_limit_reached')) {
        console.log('ğŸ§¹ Voice limit reached, attempting to clean up old voices...');
        await cleanupOldVoices();
        // Retry once after cleanup
        console.log('ğŸ”„ Retrying voice cloning after cleanup...');
        const retryResponse = await fetch('https://api.elevenlabs.io/v1/voices/add', {
          method: 'POST',
          headers: {
            'xi-api-key': ELEVENLABS_API_KEY,
          },
          body: formData,
        });
        
        if (retryResponse.ok) {
          const retryData = await retryResponse.json();
          const retryVoiceId = retryData.voice_id;
          console.log('âœ… Voice cloned successfully after cleanup! Voice ID:', retryVoiceId);
          
          // Continue with TTS generation
          const ttsResponse = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${retryVoiceId}`, {
            method: 'POST',
            headers: {
              'xi-api-key': ELEVENLABS_API_KEY,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              text,
              model_id: 'eleven_multilingual_v2',
              voice_settings: {
                stability: 0.7,
                similarity_boost: 0.8,
                style: 0.5,
                use_speaker_boost: true,
              },
            }),
          });
          
          if (ttsResponse.ok) {
            const finalAudioBuffer = await ttsResponse.arrayBuffer();
            
            // Clean up immediately
            try {
              await fetch(`https://api.elevenlabs.io/v1/voices/${retryVoiceId}`, {
                method: 'DELETE',
                headers: { 'xi-api-key': ELEVENLABS_API_KEY },
              });
              console.log('ğŸ—‘ï¸ Temporary voice cleaned up immediately');
            } catch (e) { console.warn('Failed to delete voice:', e); }
            
            return new NextResponse(finalAudioBuffer, {
              headers: {
                'Content-Type': 'audio/mpeg',
                'Content-Disposition': 'attachment; filename="cloned_voice.mp3"',
              },
            });
          }
        }
      }
      
      // Fallback to default voice
      return await generateWithDefaultVoice(text, `ElevenLabs voice cloning failed: ${cloneResponse.status} - ${errorText.substring(0, 100)}`);
    }

    const cloneData = await cloneResponse.json();
    const clonedVoiceId = cloneData.voice_id;
    
    console.log('âœ… Voice cloned successfully! Voice ID:', clonedVoiceId);
    
    // ì„¸ì…˜ë³„ ìŒì„± ìºì‹œì— ì €ì¥ (ì¬ì‚¬ìš©ì„ ìœ„í•´)
    if (sessionId) {
      sessionVoiceCache.set(sessionId, {
        voiceId: clonedVoiceId,
        createdAt: Date.now(),
        lastUsed: Date.now(),
        sampleText: text
      });
      console.log('ğŸ’¾ ì„¸ì…˜ ìŒì„± ìºì‹œì— ì €ì¥:', sessionId, '->', clonedVoiceId);
      console.log('ğŸ“Š í˜„ì¬ ìºì‹œëœ ì„¸ì…˜ë“¤:', Array.from(sessionVoiceCache.keys()));
    } else {
      console.warn('âš ï¸ sessionIdê°€ ì—†ì–´ì„œ ìºì‹œì— ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!');
    }

    // Step 2: Generate speech with cloned voice
    console.log('ğŸ—£ï¸ Step 2: Generating speech with cloned voice...');
    if (checkTimeout()) {
      console.error('âŒ Timeout before TTS generation');
      return await generateWithDefaultVoice(text);
    }
    
    const ttsResponse = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${clonedVoiceId}`, {
      method: 'POST',
      headers: {
        'xi-api-key': ELEVENLABS_API_KEY,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {
          stability: 0.7,
          similarity_boost: 0.8,
          style: 0.5,
          use_speaker_boost: true,
        },
      }),
    });

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error('âŒ TTS with cloned voice failed:', errorText);
      
      // Clean up the voice
      try {
        await fetch(`https://api.elevenlabs.io/v1/voices/${clonedVoiceId}`, {
          method: 'DELETE',
          headers: { 'xi-api-key': ELEVENLABS_API_KEY },
        });
      } catch (e) { console.warn('Failed to delete voice:', e); }
      
      return await generateWithDefaultVoice(text);
    }

    const finalAudioBuffer = await ttsResponse.arrayBuffer();
    
    const totalTime = Date.now() - startTime;
    console.log('ğŸ‰ğŸ‰ğŸ‰ VOICE CLONING COMPLETED SUCCESSFULLY! ğŸ‰ğŸ‰ğŸ‰');
    console.log('ğŸ—£ï¸ THIS IS YOUR CLONED VOICE - NOT DEFAULT VOICE!');
    console.log(`â±ï¸ Total execution time: ${totalTime}ms`);
    console.log(`ğŸ¯ Cloned voice ID used: ${clonedVoiceId}`);
    
    // ì£¼ì˜: ìŒì„±ì„ ì¦‰ì‹œ ì‚­ì œí•˜ì§€ ì•ŠìŒ (ìºì‹œëœ ìŒì„± ì¬ì‚¬ìš©ì„ ìœ„í•´)
    // 30ë¶„ í›„ ìë™ìœ¼ë¡œ ì •ë¦¬ë˜ë„ë¡ ì„¤ì •ë¨
    console.log('ğŸ’¾ ìŒì„± ìºì‹œì— ë³´ê´€ë¨ (30ë¶„ í›„ ìë™ ì •ë¦¬)');

    return new NextResponse(finalAudioBuffer, {
      headers: {
        'Content-Type': 'audio/mpeg',
        'Content-Disposition': 'inline; filename="cloned_voice.mp3"',
        'Access-Control-Allow-Origin': '*',
        'Accept-Ranges': 'bytes',
      },
    });

  } catch (error) {
    console.error('ğŸ’¥ Voice cloning error:', error);
    return await generateWithDefaultVoice(body?.text || "Hello, how are you today?");
  }
}

async function generateWithDefaultVoice(text: string, reason: string = 'Voice cloning failed') {
  try {
    console.log('ğŸš¨ğŸš¨ğŸš¨ USING DEFAULT VOICE FALLBACK - NOT USER VOICE! ğŸš¨ğŸš¨ğŸš¨');
    console.log('ğŸ”„ Reason:', reason);
    console.log('ğŸ”„ Using Rachel voice instead of user voice');
    
    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${DEFAULT_VOICE_ID}`, {
      method: 'POST',
      headers: {
        'xi-api-key': ELEVENLABS_API_KEY,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text,
        model_id: 'eleven_monolingual_v1',
        voice_settings: {
          stability: 0.7,
          similarity_boost: 0.8,
        },
      }),
    });

    if (response.ok) {
      const audioBuffer = await response.arrayBuffer();
      return new NextResponse(audioBuffer, {
        headers: {
          'Content-Type': 'audio/mpeg',
          'Content-Disposition': 'inline; filename="fallback_voice.mp3"',
          'Access-Control-Allow-Origin': '*',
          'Accept-Ranges': 'bytes',
          'X-Fallback-Reason': reason.substring(0, 200), // ì‹¤íŒ¨ ì´ìœ ë¥¼ í—¤ë”ì— í¬í•¨
        },
      });
    } else {
      const errorText = await response.text();
      console.error('âŒ Fallback voice generation failed:', errorText);
    }
  } catch (error) {
    console.error('ğŸ’¥ Fallback voice generation failed:', error);
  }

  return NextResponse.json({ error: 'All voice generation methods failed' }, { status: 500 });
}

async function cleanupOldVoices() {
  try {
    console.log('ğŸ” Fetching current voices...');
    const response = await fetch('https://api.elevenlabs.io/v1/voices', {
      headers: { 'xi-api-key': ELEVENLABS_API_KEY },
    });
    
    if (response.ok) {
      const data = await response.json();
      const userVoices = data.voices.filter((voice: any) => 
        voice.name.startsWith('user_voice_') && voice.category === 'cloned'
      );
      
      console.log(`ğŸ¯ Found ${userVoices.length} user voices to clean up`);
      
      // Delete oldest user voices (keep only the most recent 2)
      const voicesToDelete = userVoices.slice(0, -2);
      
      for (const voice of voicesToDelete) {
        try {
          await fetch(`https://api.elevenlabs.io/v1/voices/${voice.voice_id}`, {
            method: 'DELETE',
            headers: { 'xi-api-key': ELEVENLABS_API_KEY },
          });
          console.log(`ğŸ—‘ï¸ Deleted old voice: ${voice.name}`);
        } catch (e) {
          console.warn(`Failed to delete voice ${voice.name}:`, e);
        }
      }
      
      console.log('âœ… Cleanup completed');
    }
  } catch (error) {
    console.error('âŒ Cleanup failed:', error);
  }
}

// ë§Œë£Œëœ ì„¸ì…˜ ìºì‹œ ì •ë¦¬ í•¨ìˆ˜
function cleanupExpiredSessions() {
  const now = Date.now();
  const sessionsToDelete: string[] = [];
  
  for (const [sessionId, voice] of sessionVoiceCache) {
    if (now - voice.lastUsed > CACHE_TIMEOUT) {
      sessionsToDelete.push(sessionId);
      
      // ElevenLabsì—ì„œ ìŒì„± ì‚­ì œ
      fetch(`https://api.elevenlabs.io/v1/voices/${voice.voiceId}`, {
        method: 'DELETE',
        headers: { 'xi-api-key': ELEVENLABS_API_KEY },
      }).catch(e => console.warn('ìŒì„± ì‚­ì œ ì‹¤íŒ¨:', e));
    }
  }
  
  sessionsToDelete.forEach(sessionId => {
    sessionVoiceCache.delete(sessionId);
    console.log('ğŸ—‘ï¸ ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬:', sessionId);
  });
  
  if (sessionsToDelete.length > 0) {
    console.log(`âœ… ${sessionsToDelete.length}ê°œ ë§Œë£Œëœ ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ`);
  }
}

// ì •ê¸°ì  ìºì‹œ ì •ë¦¬ (10ë¶„ë§ˆë‹¤)
setInterval(cleanupExpiredSessions, 10 * 60 * 1000);